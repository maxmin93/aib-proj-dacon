{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained models: Word2Vec, FastText, Glove\n",
    "\n",
    "__사전학습모델 (이거 하나면 끝!)__\n",
    "\n",
    "- [깃허브 ratsgo/embedding](https://github.com/ratsgo/embedding/releases/tag/v1.0.1)\n",
    "  - 2019.07 [word-embeddings 다운로드](https://drive.google.com/file/d/1FeGIbSz2E1A63JZP_XIxnGaSRt7AhXFf/view)\n",
    "  - [한국어 임베딩 튜토리얼](https://ratsgo.github.io/embedding/)\n",
    "\n",
    "__그 밖에 사전학습모델 (Download)__\n",
    "\n",
    "- [국민대 자연어처리-Word2Vec,FastText](http://nlp.kookmin.ac.kr/kcc/word2vec/)\n",
    "  - Word2Vec 다운로드 가능: [word2vec-KCC150](http://203.246.112.71/kcc/word2vec/word2vec-KCC150.tar.gz)\n",
    "  - FastText 는 다운로드 안됨\n",
    "  - [임베딩 Demo](http://nlp.kookmin.ac.kr/kcc/word2vec/demo)\n",
    "- [Glove-kor 100차원 다운로드](http://nlp.stanford.edu/data/glove.6B.zip)\n",
    "  - 설명 페이지는 못찾았음\n",
    "- [fasttext.cc Resources](https://fasttext.cc/docs/en/crawl-vectors.html)\n",
    "  - FastText 다운로드 가능: [cc.ko.300.bin.gz](https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ko.300.bin.gz)\n",
    "- [깃허브 Kyubyong/wordvectors](https://github.com/Kyubyong/wordvectors)\n",
    "  - 2016.12 [Korean Word2Vec](https://drive.google.com/open?id=0B0ZXk88koS2KbDhXdWg1Q2RydlU)\n",
    "  - 2017.02 [Korean FastText](https://www.dropbox.com/s/stt4y0zcp2c0iyb/ko.tar.gz?dl=0)\n",
    "\n",
    "__참고문서__ \n",
    "\n",
    "- Word2Vec\n",
    "  - [8) 사전 훈련된 워드 임베딩(Pre-trained Word Embedding)](https://wikidocs.net/33793)\n",
    "  - [자연어처리(NLP) 14일차 (Word2Vec 실습2)](https://omicro03.medium.com/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-14%EC%9D%BC%EC%B0%A8-word2vec-%EC%8B%A4%EC%8A%B52-8e518a358b6c)\n",
    "- Glove\n",
    "  - [자연어처리(NLP) 15일차 (GloVe)](https://omicro03.medium.com/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-15%EC%9D%BC%EC%B0%A8-glove-62ecdf424bbd)\n",
    "- FastText\n",
    "  - 블로그 [FastText Pre-trained 한국어 모델 사용기](https://inahjeon.dev/fasttext/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP 모델들\n",
    "\n",
    "참고자료: [After BERT & ELECTRA 언어모델 비교 및 선정](https://mysterico.tistory.com/8)\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FAaJEI%2FbtqYpWHar6Q%2Fu9kBAMEKNjWOnVd1rlLDf0%2Fimg.png\" width=\"640\"/><br/>&nbsp;\n",
    "\n",
    "각 발표에 포함되었던 밴치마크 정리\n",
    "- BERT, XLNeT, RoBERTa, ALBERT, ELECTRA, 퍼포먼스 벤치마크(Benchmark) 비교\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbGF9C3%2FbtqUOCEfvTx%2FuiSPc5qjfgkRbqQgYM8Ijk%2Fimg.png\" width=\"840\"/><br/>&nbsp;\n",
    "\n",
    "\n",
    "### Transformer  `(Attention is all you need!!)`\n",
    "\n",
    "기존의 seq2seq의 구조인 인코더-디코더를 따르면서도, 논문의 이름처럼 어텐션(Attention)만으로 구현한 모델입니다. 이 모델은 RNN을 사용하지 않고, 인코더-디코더 구조를 설계하였음에도 번역 성능에서도 RNN보다 우수한 성능을 보여주었습니다. 대신에 Self-Attention, Multi-head Attention, Positional Encoding 등 Transformer 모델의 구성요소가 있습니다.\n",
    "\n",
    "<img src=\"https://wikidocs.net/images/page/31379/transformer4_final_final_final.PNG\" width=\"640\"/>\n",
    "\n",
    "- CNN과 RNN을 대체하는 트랜스포머\n",
    "- 트랜스포머는 요소들 사이의 패턴을 수학적으로 찾아내기 때문에 라벨링에 의한 학습과정이 필요 없음\n",
    "- 병렬 프로세싱에 적합하기 때문에 모델의 실행 속도 또한 빨라짐\n",
    "- “의미는 사물 간 관계의 결과이고, 셀프어텐션은 관계를 배우는 일반적 방법” (셀프어텐션이 핵심)\n",
    "- 명칭 유래: 데이터의 리프레젠테이션(representation)을 바꾸는 트랜스포머라고 주장한데서 유래\n",
    "\n",
    "&nbsp;\n",
    "#### BERT\n",
    "\n",
    "- 논문: [arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)\n",
    "- 설명 블로그: [dnddnjs.github.io/nlp/2019/05/08/BERT/](https://dnddnjs.github.io/nlp/2019/05/08/BERT/)<br/>&nbsp;\n",
    "\n",
    "\n",
    "Google에서 발표한 BERT는 두가지 방식으로 학습을 진행합니다.\n",
    "\n",
    "1. 앞뒤 단어들을 통해 비어있는 단어를 예측하는 방식\n",
    "  - 비어있는 단어를 Mask로 표시한다고 하여 MLM(Masked Language Model)이라고 합니다.\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbk35wz%2FbtqYur0CsIT%2FQBk4XrmBkYzn3ghWSan9Uk%2Fimg.png\" width=\"640\"/><br/>\n",
    "\n",
    "2. 이어지는 문장이 2개 주어졌을 때, 두 문장이 연결되어 있었는지 예측하는 방식\n",
    "  - NSP(Next Sentence Prediction)이라고 합니다. 자연스럽게 이어지는 문장인지 아닌지 학습하는 것입니다. (50%는 원래 연결된 문장, 50%는 랜덤하게 뽑힌 문장으로 학습)\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Ferl3lW%2FbtqYxoWn7hs%2FtTikNpMznqJ98fnPlPjjh1%2Fimg.png\" width=\"640\"/><br/>\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FAkdGA%2FbtqYB524TfQ%2FWxKEVnm2a0XBdkK7GGIUtK%2Fimg.png\" width=\"640\"/><br/>\n",
    "\n",
    "&nbsp;\n",
    "#### ELECTRA\n",
    "\n",
    "- 논문: [arxiv.org/abs/2003.10555](https://arxiv.org/abs/2003.10555)\n",
    "- 설명 블로그: [roomylee.github.io/electra](https://roomylee.github.io/electra/)\n",
    "<br/>&nbsp;\n",
    "\n",
    "Google에서 발표한 모델로 MLM을 개선시킨 RTD(Replaced Token Detection) 방식으로 학습을 진행하여 학습효율에 괄목할만한 성과를 낸 모델입니다.\n",
    "\n",
    "RTD(Replaced Token Detection)란 MLM의 MASK된 단어를 Generator로 다른 단어를 생성한 후 치환한 후 Discriminator로 원본과 맞는지 확인하는 방식으로 학습을 진행 합니다.\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc7tr0X%2FbtqYB6gDe2G%2Fv5J14MqgmWKRb6QBnXLF31%2Fimg.png\" width=\"640\"/><br/>&nbsp;\n",
    "\n",
    "이를 통해 1/4의 컴퓨팅 자원으로 RoBERTa, XLNet과 같은 성능을 냈으며 같은 자원으로는 그 이상의 성능을 성취하였습니다.\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FchZkix%2FbtqUUrpaQ42%2FNH4YZCA7BZFtvH6ZJc4wt1%2Fimg.png\" width=\"500\"/><br/>&nbsp;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('3.9.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b07c26107ec8864bc90f82b7b0852371725716d682b4b80204fd6d5ff11a363c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
